{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, io\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros de imagen y cgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de la imagen\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "img_channels = 1\n",
    "img_shape = (img_rows,img_cols,img_channels)\n",
    "# espacio latente\n",
    "latent_space = 100\n",
    "# numero de clases\n",
    "num_classes = 10\n",
    "NUM_SAMPLES = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    # input imagen\n",
    "    img_input = layers.Input(shape= img_shape)\n",
    "    # input label \n",
    "    label_input = layers.Input(shape=(1,))\n",
    "    hidden_layer = layers.Embedding(num_classes, 50)(label_input)\n",
    "    hidden_layer = layers.Dense(img_rows*img_cols)(hidden_layer)\n",
    "    hidden_layer = layers.Reshape(img_shape)(hidden_layer)\n",
    "    # unir capas\n",
    "    merge = layers.Concatenate()([img_input, hidden_layer])\n",
    "    # downsample\n",
    "    hidden_layer = layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    hidden_layer = layers.LeakyReLU(alpha=0.2)(hidden_layer)\n",
    "    # downsample\n",
    "    hidden_layer = layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(hidden_layer)\n",
    "    hidden_layer = layers.LeakyReLU(alpha=0.2)(hidden_layer)\n",
    "    # flaten features\n",
    "    hidden_layer = layers.Flatten()(hidden_layer)\n",
    "    hidden_layer = layers.Dropout(0.4)(hidden_layer)\n",
    "    # output\n",
    "    output_layer = layers.Dense(1,activation='sigmoid')(hidden_layer)\n",
    "    # define model\n",
    "    model = Model([img_input,label_input],output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    # input z\n",
    "    latent_input = layers.Input(shape=(latent_space,))\n",
    "    hidden_layer = layers.Dense(128*7*7)(latent_input)\n",
    "    hidden_layer = layers.LeakyReLU(alpha=0.2)(hidden_layer)        \n",
    "    img_layer = layers.Reshape((7,7,128))(hidden_layer)\n",
    "    # input label\n",
    "    label_input = layers.Input(shape=(1,))\n",
    "    hidden_layer = layers.Embedding(num_classes, 50)(label_input)\n",
    "    hidden_layer = layers.Dense(7*7)(hidden_layer)\n",
    "    hidden_layer = layers.Reshape((7,7,1))(hidden_layer)\n",
    "    # unir capas\n",
    "    merge = layers.Concatenate()([img_layer, hidden_layer])\n",
    "    # upsample to 14x14\n",
    "    hidden_layer = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    hidden_layer = layers.LeakyReLU(alpha=0.2)(hidden_layer)\n",
    "    # upsample to 28x28\n",
    "    hidden_layer = layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(hidden_layer)\n",
    "    hidden_layer = layers.LeakyReLU(alpha=0.2)(hidden_layer)\n",
    "    # output\n",
    "    output_layer = layers.Conv2D(1, (7,7), activation='tanh', padding='same')(hidden_layer)\n",
    "    # define model\n",
    "    model = Model([latent_input,label_input],output_layer)\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    # label real\n",
    "    label_real = tf.ones_like(real_output)\n",
    "    # smoothing class=1 to [0.7, 1.2]\n",
    "    label_real = label_real - 0.3 + (tf.random.uniform((label_real.shape)) * 0.5)\n",
    "    \n",
    "    # label fake\n",
    "    label_fake = tf.zeros_like(fake_output)\n",
    "    # smoothing class=0 to [0.0, 0.3]\n",
    "    label_fake = label_fake + (tf.random.uniform((label_fake.shape)) * 0.3)\n",
    "    \n",
    "    real_loss = cross_entropy(label_real, real_output)\n",
    "    fake_loss = cross_entropy(label_fake, fake_output)\n",
    "#     total_loss = real_loss + fake_loss\n",
    "    return real_loss, fake_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    # label real\n",
    "    label_real = tf.ones_like(fake_output)\n",
    "    # smoothing class=1 to [0.7, 1.2]\n",
    "    label_real = label_real - 0.3 + (tf.random.uniform((label_real.shape)) * 0.5)\n",
    "    return cross_entropy(label_real, fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function train per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images_batch, labels):\n",
    "    noise = tf.random.normal([BATCH_SIZE, latent_space])\n",
    "    label_random = tf.random.uniform((BATCH_SIZE,), minval=0, maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise, label_random], training=True)\n",
    "        \n",
    "        real_output = discriminator([images_batch, labels ], training=True)\n",
    "        fake_output = discriminator([generated_images, label_random], training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        real_loss, fake_loss = discriminator_loss(real_output, fake_output)\n",
    "        disc_loss = real_loss + fake_loss\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    # sum loss per batch\n",
    "    loss_generator(gen_loss)\n",
    "    loss_discriminator_real(real_loss)\n",
    "    loss_discriminator_fake(fake_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function training net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epoch):\n",
    "    for i in range(epoch):\n",
    "        start = time.time()\n",
    "        for image_batch, labels in dataset:\n",
    "            train_step(image_batch, labels)\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            # write loss values\n",
    "            tf.summary.scalar('loss generator', loss_generator.result(), step=i)\n",
    "            tf.summary.scalar('loss discriminator real', loss_discriminator_real.result(), step=i)\n",
    "            tf.summary.scalar('loss discriminator fake', loss_discriminator_fake.result(), step=i)\n",
    "            \n",
    "        template = 'Epoch {}, Loss generator: {}, Loss discriminator real: {}, Loss discriminator fake {}, Time: {}'\n",
    "        print (template.format(i+1,\n",
    "                         loss_generator.result(), \n",
    "                         loss_discriminator_real.result(),\n",
    "                         loss_discriminator_fake.result(),\n",
    "                         time.time()-start))\n",
    "        # Save the model every 100 epochs\n",
    "        if( (i + 1) % 2 == 0 or i == 0):\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            images_example, labels_example = generated_samples_images()\n",
    "            figure = image_grid(images_example, labels_example)\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.image(\"Epoch {}\".format(i+1), plot_to_image(figure), step=i+1)\n",
    "        \n",
    "        loss_generator.reset_states()\n",
    "        loss_discriminator_real.reset_states()\n",
    "        loss_discriminator_fake.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to print images samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def image_grid(samples, label_samples):\n",
    "    \"\"\"Return a 3x3 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "    # Create a figure to contain the plot.\n",
    "    figure = plt.figure(figsize=(12,12))\n",
    "    for i in range(NUM_SAMPLES):\n",
    "        # Start next subplot.\n",
    "        plt.subplot(3, 3, i + 1, title=class_names[label_samples[i]])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(samples[i], cmap=plt.cm.binary)\n",
    "#     plt.savefig(\"{}.png\".format(name), format='png')\n",
    "    return figure\n",
    "\n",
    "def generated_samples_images():\n",
    "    samples = tf.random.normal([NUM_SAMPLES, latent_space])\n",
    "    label_samples = tf.random.uniform((NUM_SAMPLES,), minval=0, maxval=num_classes, dtype=tf.dtypes.int32)\n",
    "    generated_samples = generator([samples, label_samples], training=False)\n",
    "    generated_samples = 127.5*generated_samples + 127.5\n",
    "    generated_samples = tf.dtypes.cast(generated_samples, tf.int32)\n",
    "    generated_samples = tf.reshape(generated_samples,[NUM_SAMPLES,img_rows,img_cols])\n",
    "    return generated_samples, label_samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples():\n",
    "    (x_train, y_train), (_, _) = fashion_mnist.load_data()    \n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train = (x_train - 127.5) / 127.5\n",
    "    # Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    return x_train, y_train, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_generator = tf.keras.metrics.Mean('loss_generator', dtype=tf.float32)\n",
    "loss_discriminator_real = tf.keras.metrics.Mean('loss_discriminator_real', dtype=tf.float32)\n",
    "loss_discriminator_fake = tf.keras.metrics.Mean('loss_discriminator_fake', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5) \n",
    "discriminator_optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0005, momentum = 0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_generator()\n",
    "discriminator = create_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save values curve loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/train/' + current_time\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 128\n",
    "x_train, y_train, class_names = load_samples()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train cgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50\n",
    "train(train_dataset, NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
